对损失函数求偏导，就能得到如下式子：
![[Pasted image 20240329091658.png]]
然后就可以用来更新w的值。
![[Pasted image 20240329095402.png]]
效果如上。但是实际过程中，一般不会用所有样本的平均损失来计算梯度，因为平均损失的梯度有时候会落入鞍点，导致无法找到最小值，所以一般不取平均，而是使用**随机梯度下降**
![[Pasted image 20240329100258.png]]
由于样本本身有噪声，就可能导致跳出鞍点，找到最小值，相当于让系数的更新不那么稳定，而是添加一些抖动，使得落入鞍点后能跳出。
![[Pasted image 20240329101923.png]]
随机梯度下降虽然性能好，但是每次w的更新跟上次有依赖关系，计算每个梯度无法并行化，导致计算比较慢，所以实际使用时就会折衷一下，每次用一组样本求梯度来更新w，即**mini-batch**算法。