用来解决分类问题。
![[Pasted image 20240627081830.png]]
分类问题中，输出为概率，所以输出要属于[0, 1]，所以使用logistic函数来输出：
![[Pasted image 20240627082711.png]]
logistic函数属于sigmoid函数的一种，各种sigmoid方程：
![[Pasted image 20240627083001.png]]
逻辑斯蒂回归模型只是比普通计算图多了一个逻辑斯蒂函数：
![[Pasted image 20240627083127.png]]
损失函数也要改变，以前的损失函数是计算预测值和真实值之间的距离，现在是要计算两个分布之间的差异，二分类所用的损失函数为BCE，可以表示两个分布之间的距离，<span style="color:#c00000">这样就可以在训练时让两个分布尽可能接近</span>
![[Pasted image 20240627083614.png]]
分布之间的差异，有多种度量方式，比如KL散度、Cross-entropy(交叉熵)，BCE(二分类交叉熵)，交叉熵计算如下：
![[Pasted image 20240627083946.png]]
其中，D和T分别是两种分布。
代码实现：
![[Pasted image 20240627084646.png]]
其实就加了个sigmoid函数变换。
在计算损失时，用的是BCE：
![[Pasted image 20240627084738.png]]
