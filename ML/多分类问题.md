多分类问题中，直观想法是对每一个输出加个sigmoid，但是这样会导致最后所有输出加起来概率不是1。解决办法是前面的层用sigmoid，最后输出层用softmax。![[Pasted image 20240629091722.png]]
softmax确保了输出大于零，且加起来等于1。损失怎么算：
![[Pasted image 20240629092610.png]]

![[Pasted image 20240629094359.png]]
